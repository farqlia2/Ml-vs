{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders \n",
    "\n",
    "One of the models used for generative modeling is *autoencoder*. It consists of **encoder** part, which tries to encode an item in a latent space, and **decoder**, which turns this latent representation back to the original space, trying to re-create it. This way, we can only use a decoder part to generate totally new items. \n",
    "\n",
    "Encodings are also called *embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import models\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs = imgs.astype(\"float32\") / 255.0\n",
    "    imgs = np.pad(imgs, ((0, 0), (2, 2), (2, 2)), constant_values=0.0)\n",
    "    imgs = np.expand_dims(imgs, -1)\n",
    "    return imgs \n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoencoder Architecture\n",
    "It will consist of *encoder* + *decoder*, where the training process will consist of reconstructing the original input. This way, the network will learn the latent representation of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = layers.Input(\n",
    "    shape=(32, 32, 1), name=\"encoder_input\"\n",
    ")\n",
    "# We can think of each filter as capturing \n",
    "# a different set of characteristics \n",
    "x = layers.Conv2D(filters=32, kernel_size=(3, 3), strides=2, activation='relu', padding='same')(encoder_input)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "encoder_output = layers.Dense(2, name='encoder_output')(x)\n",
    "\n",
    "encoder = models.Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " encoder_output (Dense)      (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,770\n",
      "Trainable params: 96,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 128)\n"
     ]
    }
   ],
   "source": [
    "print(shape_before_flattening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = layers.Input(2, name='decoder_input')\n",
    "\n",
    "x = layers.Dense(shape_before_flattening)(decoder_input)\n",
    "x = layers.Reshape(target_shape=(4, 4, 128))\n",
    "x = layers.Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "decoder_output = layers.Conv2D(1, (3, 3), strides=1, activation='sigmoid', padding='same', name='decoder_output')(x)\n",
    "\n",
    "decoder = models.Model(decoder_input, decoder_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataCampTutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
