{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, \n",
    "                                                    y_train, test_size=.3,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28)\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db13e20970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='Greys')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the handwritten number is a classification problem. This is why we have to encode the numbers 0-9 as categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784).astype('float')\n",
    "X_valid = X_valid.reshape(-1, 784).astype('float')\n",
    "X_test = X_test.reshape(-1, 784).astype('float')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_valid /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "n_classes=10\n",
    "\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_valid = to_categorical(y_valid, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (784, )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 5s 3ms/step - loss: 1.1899 - accuracy: 0.6292 - val_loss: 0.5867 - val_accuracy: 0.8490\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.4930 - accuracy: 0.8668 - val_loss: 0.4023 - val_accuracy: 0.8883\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 3s 3ms/step - loss: 0.3875 - accuracy: 0.8911 - val_loss: 0.3499 - val_accuracy: 0.9018\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.3468 - accuracy: 0.9032 - val_loss: 0.3217 - val_accuracy: 0.9076\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.9083 - val_loss: 0.3030 - val_accuracy: 0.9124\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.3087 - accuracy: 0.9128 - val_loss: 0.2976 - val_accuracy: 0.9142\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.2972 - accuracy: 0.9151 - val_loss: 0.2842 - val_accuracy: 0.9187\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.2885 - accuracy: 0.9175 - val_loss: 0.2790 - val_accuracy: 0.9188\n",
      "Epoch 9/10\n",
      "1313/1313 [==============================] - 4s 3ms/step - loss: 0.2819 - accuracy: 0.9200 - val_loss: 0.2727 - val_accuracy: 0.9211\n",
      "Epoch 10/10\n",
      "1313/1313 [==============================] - 3s 3ms/step - loss: 0.2758 - accuracy: 0.9213 - val_loss: 0.2703 - val_accuracy: 0.9230\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1db19a96b30>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(111)\n",
    "\n",
    "epochs = list(range(10))\n",
    "plt.plot(epochs, history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step\n",
      "[[7.8888115e-05 5.7185310e-09 2.2658511e-04 3.9844918e-03 1.9134852e-07\n",
      "  6.8699585e-05 5.9003691e-10 9.9552709e-01 6.3178809e-06 1.0759861e-04]]\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(X_valid[0].reshape(1, 784))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_valid[0].reshape(28, 28), cmap='Greys')\n",
    "print(pred)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(range(10), pred[0])\n",
    "print(np.argmax(pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Hyperparameters \n",
    "\n",
    "We can set hyperparameters to many different values. To find the most optimal ones, we can try using random search and test those on validation set or k-fold-cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "print(housing['data'].shape)\n",
    "print(housing['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target,\n",
    "                                                    shuffle=True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, \n",
    "                                                    y_train_full,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_valid)\n",
    "_ = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_7864\\2189228328.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = tf.keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = tf.keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 11740391066381287493206016.0000 - val_loss: 1994702962495036850176.0000\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 453704553963441881088.0000 - val_loss: 25257767808014483456.0000\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 5744985638524944384.0000 - val_loss: 319823537105797120.0000\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 72745269841625088.0000 - val_loss: 4049717684076544.0000\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 921127878656000.0000 - val_loss: 51279204188160.0000\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 11663668412416.0000 - val_loss: 649315418112.0000\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 147689570304.0000 - val_loss: 8221873664.0000\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1870098048.0000 - val_loss: 104109280.0000\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 23679862.0000 - val_loss: 1318353.1250\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 299844.9375 - val_loss: 16707.8145\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 16692.0859\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=10, \n",
    "              validation_data=(X_valid, y_valid), \n",
    "              callbacks=[EarlyStopping(patience=2)])\n",
    "\n",
    "mse_test = keras_reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 4ms/step - loss: inf - val_loss: inf\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 32462999302076319671550243973890048.0000 - val_loss: 10609836404984510011926380544.0000\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 619420193985064945347198976.0000 - val_loss: 202444227152814538752.0000\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 11819033117010690048.0000 - val_loss: 3862794076160.0000\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 225516404736.0000 - val_loss: 73721.4766\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4304.1729 - val_loss: 1.3669\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3451 - val_loss: 1.3636\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3452 - val_loss: 1.3656\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3455 - val_loss: 1.3654\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.2901\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: inf - val_loss: 2704474372405081015220296029831168.0000\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 157891776013581757196566911778816.0000 - val_loss: 51603604401325826944008192.0000\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3012700336609656439832576.0000 - val_loss: 984637195526602752.0000\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 57484817247240192.0000 - val_loss: 18787670016.0000\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1096855296.0000 - val_loss: 358.9935\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 22.2444 - val_loss: 1.3676\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3146 - val_loss: 1.3626\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3149 - val_loss: 1.3688\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3152 - val_loss: 1.3659\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.3506\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 85658399932416.0000 - val_loss: 3120509440.0000\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2702815744.0000 - val_loss: 2320840448.0000\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2010183296.0000 - val_loss: 1726095104.0000\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1495048832.0000 - val_loss: 1283760384.0000\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1111922176.0000 - val_loss: 954780224.0000\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 826977408.0000 - val_loss: 710105792.0000\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 615053504.0000 - val_loss: 528132032.0000\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 457437888.0000 - val_loss: 392791296.0000\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 340213120.0000 - val_loss: 292133504.0000\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 253028992.0000 - val_loss: 217270672.0000\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 217269696.0000\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 927651397632.0000 - val_loss: 26647490.0000\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 23081026.0000 - val_loss: 19818664.0000\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 17166206.0000 - val_loss: 14739841.0000\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 12767146.0000 - val_loss: 10962528.0000\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 9495399.0000 - val_loss: 8153206.0000\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7062078.5000 - val_loss: 6063811.5000\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5252328.0000 - val_loss: 4509852.0000\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3906350.0000 - val_loss: 3354126.0000\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2905296.5000 - val_loss: 2494569.7500\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2160777.0000 - val_loss: 1855287.1250\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1855461.0000\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 317325446687490048.0000 - val_loss: 28648572715008.0000\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 24813900922880.0000 - val_loss: 21306990919680.0000\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 18455000514560.0000 - val_loss: 15846815563776.0000\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 13725665853440.0000 - val_loss: 11785835905024.0000\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 10208264847360.0000 - val_loss: 8765557440512.0000\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7592256471040.0000 - val_loss: 6519267524608.0000\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 5646642577408.0000 - val_loss: 4848615948288.0000\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 4199617921024.0000 - val_loss: 3606095069184.0000\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 3123412992000.0000 - val_loss: 2681991331840.0000\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 2322997968896.0000 - val_loss: 1994693541888.0000\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1994693672960.0000\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/242 [=======================>......] - ETA: 0s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\julia\\VSCode\\ML\\models\\Model.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m params_distribs \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_hidden\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_neurons\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marray([\u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m]),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: reciprocal(\u001b[39m3e-4\u001b[39m, \u001b[39m3e-2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m rnd_search \u001b[39m=\u001b[39m RandomizedSearchCV(keras_reg, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 params_distribs, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                 n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m rnd_search\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m validation_data\u001b[39m=\u001b[39;49m(X_valid, y_valid),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m callbacks\u001b[39m=\u001b[39;49m[EarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/julia/VSCode/ML/models/Model.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1765\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1767\u001b[0m         ParameterSampler(\n\u001b[0;32m   1768\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1769\u001b[0m         )\n\u001b[0;32m   1770\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:175\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m fit_args \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(Sequential\u001b[39m.\u001b[39mfit))\n\u001b[0;32m    173\u001b[0m fit_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 175\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\julia\\anaconda3\\envs\\DataCampTutorials\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "params_distribs = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': np.array([10, 20]),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(keras_reg, \n",
    "                                params_distribs, \n",
    "                                n_iter=10, cv=3)\n",
    "rnd_search.fit(X_train, y_train, epochs=10, \n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[EarlyStopping(patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0011800629361042776, 'n_hidden': 1, 'n_neurons': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_data = pd.read_csv('../data/games_tourney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>home</th>\n",
       "      <th>seed_diff</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>288</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>5929</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>9884</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>73</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>3920</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_1  team_2  home  seed_diff  score_diff  score_1  score_2  won\n",
       "0    1985     288      73     0         -3          -9       41       50    0\n",
       "1    1985    5929      73     0          4           6       61       55    1\n",
       "2    1985    9884      73     0          5          -4       59       63    0\n",
       "3    1985      73     288     0          3           9       50       41    1\n",
       "4    1985    3920     410     0          1          -9       54       63    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4234, 9)\n"
     ]
    }
   ],
   "source": [
    "print(season_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = season_data['seed_diff']\n",
    "y = season_data['score_diff']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to choosing appropriate train and test sample sizes\n",
    "1. If you have very small dataset, you should use cross validation\n",
    "2. If the dataset is large enough, you may use 80/20 split (Pareto rule). The training set may be further split to test the performance on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here this model is the same as linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_tensor = Input(shape=(1,))\n",
    "output_tensor = Dense(1)(input_tensor)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "          batch_size=64, \n",
    "          validation_split=.2,\n",
    "          verbose=False,\n",
    "          epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "ax.plot(np.arange(epochs), history.history['loss'], c='red', label='train loss')\n",
    "\n",
    "# twin_ax = ax.twinx()\n",
    "ax.plot(np.arange(epochs), history.history['val_loss'], label='validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "_ = plt.title('Model fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 9.2710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.271003723144531"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_7864\\2752477510.py:6: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  X_train[:, np.newaxis], y_train[:, np.newaxis],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.3483583 , 9.36959447, 9.51912314, 8.70292542, 8.58615697])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "scores = - cross_val_score(lin_reg, \n",
    "                         X_train[:, np.newaxis], y_train[:, np.newaxis],\n",
    "                         cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_7864\\51532542.py:1: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  X_train[:, np.newaxis].shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2963, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, np.newaxis].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataCampTutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
